{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e25a1e4-27b4-4a31-9048-f2b88ebab1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\programdata\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in d:\\programdata\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: openai in d:\\programdata\\anaconda3\\lib\\site-packages (1.99.9)\n",
      "Requirement already satisfied: faiss-cpu in d:\\programdata\\anaconda3\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: tiktoken in d:\\programdata\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: pypdf in d:\\programdata\\anaconda3\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community openai faiss-cpu tiktoken pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a6009c-92e3-48a4-bbc6-f168c0e902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import dependencies\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb5b0a9-e750-4bd9-9c34-83eaf7681d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key loaded successfully (will not be displayed)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load API Key from .env file & load API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the contents of the .env file into system environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the key from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "print(\"✅ API Key loaded successfully (will not be displayed)\")\n",
    "\n",
    "# Windows-specific: avoid MKL/OpenMP conflicts\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0045e43-1da8-4c30-929f-12094c4408b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files will be loaded:\n",
      " - C:/Users/syk_5/main_SS.pdf\n",
      " - C:/Users/syk_5/Resume.pdf\n",
      "Total pages loaded: 34\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Select multiple PDFs via system dialog (tkinter)\n",
    "from tkinter import Tk, filedialog\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# open dialog\n",
    "root = Tk(); root.withdraw()\n",
    "pdf_paths = filedialog.askopenfilenames(\n",
    "    title=\"Select PDF files\",\n",
    "    filetypes=[(\"PDF files\", \"*.pdf\")]\n",
    ")\n",
    "root.destroy()\n",
    "\n",
    "pdf_paths = list(pdf_paths)\n",
    "if not pdf_paths:\n",
    "    raise SystemExit(\"No PDF selected. Exiting.\")\n",
    "\n",
    "print(\"The following files will be loaded:\")\n",
    "for p in pdf_paths:\n",
    "    print(\" -\", p)\n",
    "\n",
    "# load all, keep filename+page metadata\n",
    "documents = []\n",
    "for path in pdf_paths:\n",
    "    docs = PyPDFLoader(path).load()\n",
    "    for d in docs:\n",
    "        d.metadata[\"source\"] = os.path.basename(d.metadata.get(\"source\", path))\n",
    "    documents.extend(docs)\n",
    "print(f\"Total pages loaded: {len(documents)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85872b30-81bb-41bc-b6f3-a2e0b4913a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287d2f9d-b990-4967-967d-007ad6ba2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate vector database\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "babae67d-5e49-4df4-8ee3-ee1210e5d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build a controllable RAG chain with chat memory (LCEL) — add snippets\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                      # optional: more diverse retrieval\n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 30, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, timeout=60, max_retries=1)\n",
    "\n",
    "#SYSTEM = \"\"\"You must answer ONLY using the provided context.\n",
    "#If the answer is not contained in the context, say \"I don't know.\"\n",
    "#Cite sources like [filename p.X] after claims when possible.\"\"\"\n",
    "SYSTEM = \"\"\"\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "def format_docs(docs, max_chars=1200):\n",
    "    rows, seen = [], set()\n",
    "    for d in docs:\n",
    "        meta = d.metadata or {}\n",
    "        name = Path(meta.get(\"source\", \"doc\")).name\n",
    "        page = meta.get(\"page\")\n",
    "        tag = f\"[{name} p.{(page + 1) if isinstance(page, int) else '?'}]\"\n",
    "        text = d.page_content\n",
    "        key = (name, page, hash(text[:120]))  # light de-dup\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if len(text) > max_chars:\n",
    "            text = text[:max_chars] + \" ...\"\n",
    "        rows.append(f\"{tag}\\n{text}\")\n",
    "    return \"\\n\\n\".join(rows)\n",
    "\n",
    "# Core pipeline:\n",
    "rag_core = (\n",
    "    # 1) pass through fields\n",
    "    RunnableMap({\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x.get(\"chat_history\", []),\n",
    "    })\n",
    "    # 2) retrieve\n",
    "    | RunnableMap({\n",
    "        \"docs\":       lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\":   lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    })\n",
    "    # 3) build LLM context\n",
    "    | RunnableMap({\n",
    "        \"context\":      lambda x: format_docs(x[\"docs\"]),\n",
    "        \"question\":     lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"docs\":         lambda x: x[\"docs\"],    # keep docs for outputs below\n",
    "    })\n",
    "    # 4) in parallel: produce answer + pass through docs + expose snippets/sources\n",
    "    | RunnableMap({\n",
    "        \"answer\":   (prompt | llm | StrOutputParser()),\n",
    "        \"docs\":     lambda x: x[\"docs\"],\n",
    "        # NEW: raw text snippets returned to the caller\n",
    "        \"snippets\": lambda x: [d.page_content for d in x[\"docs\"]],\n",
    "        # Optional convenience: structured sources (filename + page)\n",
    "        \"sources\":  lambda x: [\n",
    "            {\n",
    "                \"source\": Path((d.metadata or {}).get(\"source\", \"doc\")).name,\n",
    "                \"page\":   ((d.metadata or {}).get(\"page\") + 1) if isinstance((d.metadata or {}).get(\"page\"), int) else None\n",
    "            }\n",
    "            for d in x[\"docs\"]\n",
    "        ],\n",
    "    })\n",
    ")\n",
    "\n",
    "# memory wrapper\n",
    "_store = {}\n",
    "def _get_history(session_id: str):\n",
    "    if session_id not in _store:\n",
    "        _store[session_id] = ChatMessageHistory()\n",
    "    return _store[session_id]\n",
    "\n",
    "qa = RunnableWithMessageHistory(\n",
    "    rag_core,\n",
    "    get_session_history=_get_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"  # important to silence tracer expecting 'output'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9229e468-0db0-43a9-962c-cd7510de5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat mode started. Press Enter on an empty line to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Statistically feasible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The term \"statistically feasible\" in this context refers to problems that are theoretically solvable using statistical methods, but may not have computationally efficient procedures for solving them. In other words, while the statistical theory may suggest that a problem can be solved, the practical implementation of solving it computationally may be challenging or not well-established. \n",
      "\n",
      "Sources:\n",
      "  - main_SS.pdf p.8\n",
      "  - main_SS.pdf p.20\n",
      "  - main_SS.pdf p.28\n",
      "  - main_SS.pdf p.23\n",
      "  - main_SS.pdf p.33\n",
      "\n",
      "Retrieved snippets:\n",
      "  [1] condition ∥R∥F →∞ is therefore not sufficient.\n",
      "2.2 Computational Feasibility\n",
      "The results in Section 2.1 provides a necessary condition for statistical detectability. There are, however, numerous\n",
      "problems that are statistically feasible with ...\n",
      "  [2] are correlated. This conclusion, while biologically relevant, is also certainly expected.\n",
      "20\n",
      "  [3] Van der Vaart, A. W. (2000). Asymptotic statistics, Volume 3. Cambridge university press.\n",
      "Varshney, L. R., B. L. Chen, E. Paniagua, D. H. Hall, and D. B. Chklovskii (2011). Structural properties of the\n",
      "caenorhabditis elegans neuronal networ ...\n",
      "  [4] an approximate p-value of 5 ×10−4. We thus reject the null hypothesis in favor of the alternative hypothesis that\n",
      "the English and French Wikipedia networks are correlated.\n",
      "We next quantify the degree of correlations between the edges of Ae  ...\n",
      "  [5] standard normals. In other words we have\n",
      "X\n",
      "k≤ℓ\n",
      "nkℓˆρ2\n",
      "kℓ\n",
      "d\n",
      "→χ2\n",
      "K(K+1)/2\n",
      "under H0. Next suppose that the alternative hypothesis is true and that there exists a constant µ> 0 such that\n",
      "X\n",
      "k≤ℓ\n",
      "nkℓρ2\n",
      "kℓ →µ.\n",
      "Then for any k,ℓ, the term √nkℓρkℓ is  ...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Compuationally feasible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: In the context provided, \"computationally feasible\" refers to problems that can be solved using computational methods, even though there may not be efficient procedures established for solving them. The passage mentions that there are problems that are statistically feasible, meaning they can be theoretically solved using statistical methods, but may lack computationally efficient procedures for solving them. Examples of such problems include community detection, sparse PCA, and estimation in spiked tensor models.\n",
      "\n",
      "The passage also discusses a statistical vs. computational gap, where the problem of independence testing is transformed into the planted clique detection problem in theoretical computer science. This transformation highlights the challenge of bridging the gap between statistical feasibility and computational feasibility in certain problems. \n",
      "\n",
      "Sources:\n",
      "  - main_SS.pdf p.8\n",
      "  - main_SS.pdf p.20\n",
      "  - main_SS.pdf p.27\n",
      "  - main_SS.pdf p.8\n",
      "  - main_SS.pdf p.28\n",
      "\n",
      "Retrieved snippets:\n",
      "  [1] condition ∥R∥F →∞ is therefore not sufficient.\n",
      "2.2 Computational Feasibility\n",
      "The results in Section 2.1 provides a necessary condition for statistical detectability. There are, however, numerous\n",
      "problems that are statistically feasible with ...\n",
      "  [2] are correlated. This conclusion, while biologically relevant, is also certainly expected.\n",
      "20\n",
      "  [3] Journal of Machine Learning Research 15 , 3513–3540.\n",
      "Lyzinski, V. and D. L. Sussman (2020). Matchability of heterogeneous networks pairs. Information and Inference:\n",
      "A Journal of the IMA 9 , 749–783.\n",
      "27\n",
      "  [4] s0 ≥0, select a subset of s0 vertices of S and form a clique between these s0 vertices. Suppose we are now given a\n",
      "8\n",
      "  [5] Van der Vaart, A. W. (2000). Asymptotic statistics, Volume 3. Cambridge university press.\n",
      "Varshney, L. R., B. L. Chen, E. Paniagua, D. H. Hall, and D. B. Chklovskii (2011). Structural properties of the\n",
      "caenorhabditis elegans neuronal networ ...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the trade-off between them?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The trade-off between statistical feasibility and computational feasibility lies in the balance between the theoretical ability to solve a problem using statistical methods and the practical ability to implement those solutions computationally. \n",
      "\n",
      "Statistical feasibility focuses on the theoretical aspects of solving a problem using statistical techniques, such as hypothesis testing, estimation, or inference. These methods are grounded in statistical theory and provide insights into the underlying data generating processes.\n",
      "\n",
      "On the other hand, computational feasibility deals with the practical implementation of statistical methods to solve real-world problems. This involves considerations such as algorithm efficiency, computational resources, and scalability. While a problem may be statistically feasible in theory, it may not always be computationally feasible due to constraints such as time complexity, memory requirements, or the availability of suitable algorithms.\n",
      "\n",
      "Finding the right balance between statistical and computational feasibility is crucial in research and data analysis. Researchers often need to make trade-offs between statistical accuracy and computational efficiency when designing and implementing solutions to complex problems. \n",
      "\n",
      "Sources:\n",
      "  - main_SS.pdf p.20\n",
      "  - main_SS.pdf p.23\n",
      "  - main_SS.pdf p.27\n",
      "  - main_SS.pdf p.24\n",
      "  - main_SS.pdf p.6\n",
      "\n",
      "Retrieved snippets:\n",
      "  [1] are correlated. This conclusion, while biologically relevant, is also certainly expected.\n",
      "20\n",
      "  [2] obtain a ROC curve and associated AUC for link prediction using both ˆP(sub) and ˆR(sub). We perform the above\n",
      "AUC calculations 100 times, each time choosing a random subset of entries Eto set to 0. The average AUC when\n",
      "using only ˆP(sub) i ...\n",
      "  [3] Journal of Machine Learning Research 15 , 3513–3540.\n",
      "Lyzinski, V. and D. L. Sussman (2020). Matchability of heterogeneous networks pairs. Information and Inference:\n",
      "A Journal of the IMA 9 , 749–783.\n",
      "27\n",
      "  [4] magnitude of ∥R∥F itself is not sufficiently refined to distinguish between the simple and more difficult settings for\n",
      "24\n",
      "  [5] H 2(Pn,Qn) = O(1) as n→∞ where H denote the Hellinger distance between distributions; see e.g., Eq. (1.6) in\n",
      "Oosterhoff and van Zwet (2012) for more details. We then have the following result (see the appendix for a proof).\n",
      "Theorem 1. Let { ...\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Interactive loop (blank line to exit)\n",
    "session_id = \"default_session\"\n",
    "\n",
    "print(\"Chat mode started. Press Enter on an empty line to exit.\\n\")\n",
    "while True:\n",
    "    query = input(\"You: \").strip()\n",
    "    if query == \"\":\n",
    "        print(\"Bye.\")\n",
    "        break\n",
    "\n",
    "    res = qa.invoke(\n",
    "        {\"question\": query},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    # res includes: answer (str), docs (List[Document]), snippets (List[str]), sources (List[dict])\n",
    "    print(\"Bot:\", res[\"answer\"], \"\\n\")\n",
    "\n",
    "    # Optional: show normalized sources\n",
    "    if \"sources\" in res:\n",
    "        print(\"Sources:\")\n",
    "        for s in res[\"sources\"]:\n",
    "            p = f\" p.{s['page']}\" if s.get(\"page\") else \"\"\n",
    "            print(f\"  - {s['source']}{p}\")\n",
    "        print()\n",
    "\n",
    "    # NEW: show retrieved snippets (trim for readability)\n",
    "    if \"snippets\" in res:\n",
    "        print(\"Retrieved snippets:\")\n",
    "        MAX_PREVIEW = 240\n",
    "        for i, snip in enumerate(res[\"snippets\"], 1):\n",
    "            preview = snip if len(snip) <= MAX_PREVIEW else snip[:MAX_PREVIEW] + \" ...\"\n",
    "            print(f\"  [{i}] {preview}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f9086-734d-45d2-9085-5917ce8b2fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
